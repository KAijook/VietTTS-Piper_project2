import sys
import types

try:
    # C·∫ßn cho Gradio/websockets trong m·ªôt s·ªë m√¥i tr∆∞·ªùng
    import websockets.asyncio
except ModuleNotFoundError:
    import websockets
    sys.modules["websockets.asyncio"] = types.ModuleType("websockets.asyncio")
    sys.modules["websockets.asyncio"].__dict__.update(websockets.__dict__)

import gradio as gr
import tempfile
import requests
import os
import subprocess
import tarfile
import soundfile as sf
import noisereduce as nr
from pydub import AudioSegment, effects
from pedalboard import Pedalboard, Reverb
from pedalboard.io import AudioFile
import json

# --- Story Database ---
STORY_FILE = "stories.json"
STORIES = {"Kh√¥ng c√≥ truy·ªán": "Ch∆∞a t·∫£i stories.json l√™n!"} # Kh·ªüi t·∫°o gi√° tr·ªã m·∫∑c ƒë·ªãnh

if os.path.exists(STORY_FILE):
    try:
        with open(STORY_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
            if isinstance(data, dict):
                STORIES = data
    except json.JSONDecodeError:
        pass
    except Exception as e:
        pass

# --- Config ---
PIPER_TAR  = "piper_linux_x86_64.tar.gz"  # T√™n file n√©n Piper
PIPER_DIR  = "./piper_bin"
PIPER_BIN  = os.path.join(PIPER_DIR, "piper")

MODEL_CHOICES = {
    "VIVOS X Low": "models/vi_VN-vivos-x_low.onnx",
    "25hours Single Low": "models/vi_VN-25hours_single-low.onnx",
    "VAIS1000 Medium": "models/vi_VN-vais1000-medium.onnx"
}

# --- Setup Piper ---
def safe_extract(tar, path=".", members=None):
    for member in tar.getmembers():
        member_path = os.path.join(path, member.name)
        if not os.path.commonprefix([os.path.abspath(path), os.path.abspath(member_path)]) == os.path.abspath(path):
            raise Exception("Path Traversal detected in tar file!")
    tar.extractall(path, members)

def setup_piper():
    if not os.path.exists(PIPER_DIR):
        os.makedirs(PIPER_DIR, exist_ok=True)

    local_piper = None
    if not os.path.exists(PIPER_BIN):
        if not os.path.exists(PIPER_TAR):
            raise RuntimeError("Piper binary or archive missing.") 

        with tarfile.open(PIPER_TAR, "r:gz") as tar:
            safe_extract(tar, PIPER_DIR)

    for root, dirs, files in os.walk(PIPER_DIR):
        if "piper" in files:
            local_piper = os.path.join(root, "piper")
            break

    if not local_piper:
        raise RuntimeError("Piper binary not found after extraction.")

    os.chmod(local_piper, 0o755)
    os.environ["LD_LIBRARY_PATH"] = f"{os.path.dirname(local_piper)}:{os.environ.get('LD_LIBRARY_PATH','')}"

    return local_piper

PIPER_BIN = setup_piper()

# --- Postprocess audio ---
def postprocess_audio(input_path, output_path):
    data, sr = sf.read(input_path)
    
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=True) as tmp_clean_file:
        tmp_clean_path = tmp_clean_file.name
        
        # 1. Gi·∫£m nhi·ªÖu (Noise Reduction)
        reduced = nr.reduce_noise(y=data, sr=sr)
        sf.write(tmp_clean_path, reduced, sr)

        with tempfile.NamedTemporaryFile(suffix=".wav", delete=True) as tmp_compressed_file:
            tmp_compressed_path = tmp_compressed_file.name
            
            # 2. N√©n d·∫£i ƒë·ªông (Dynamic Range Compression)
            audio = AudioSegment.from_wav(tmp_clean_path)
            compressed = effects.compress_dynamic_range(audio)
            compressed.export(tmp_compressed_path, format="wav")

            # 3. Th√™m Reverb (hi·ªáu ·ª©ng √¢m thanh)
            with AudioFile(tmp_compressed_path) as f:
                audio_np = f.read(f.frames)
                sr = f.samplerate

            board = Pedalboard([Reverb(room_size=0.2, wet_level=0.15, dry_level=0.85)])
            effected = board(audio_np, sr)

            with AudioFile(output_path, "w", sr, effected.shape[0]) as f:
                f.write(effected)

# --- TTS ---
def text_to_speech(text, model_choice, length_scale=0.7, noise_scale=0.8, noise_w=0.8, sentence_silence=0.5):
    try:
        model_path = MODEL_CHOICES[model_choice]
        final_output = "output_final.wav"

        # Ki·ªÉm tra s·ª± t·ªìn t·∫°i c·ªßa Piper v√† Model
        if not os.path.exists(PIPER_BIN) or not os.path.exists(model_path):
            return None
        
        # Ch·∫°y Piper trong file t·∫°m
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_piper_output:
            output_file = tmp_piper_output.name

            cmd = [
                PIPER_BIN,
                "--model", model_path,
                "--output_file", output_file,
                "--length_scale", str(length_scale),
                "--noise_scale", str(noise_scale),
                "--noise_w", str(noise_w),
                "--sentence_silence", str(sentence_silence)
            ]
            result = subprocess.run(cmd, input=text.encode("utf-8"),
                                    stdout=subprocess.PIPE, stderr=subprocess.PIPE)

            if result.returncode != 0:
                os.remove(output_file) if os.path.exists(output_file) else None
                return None

            if not os.path.exists(output_file):
                return None
            
            # Post-process v√† d·ªçn d·∫πp
            postprocess_audio(output_file, final_output)
            os.remove(output_file)
            
            return final_output
    except Exception as e:
        return None
        
# --- L∆∞u l·ªãch s·ª≠ ---
if not os.path.exists("audios"):
    os.makedirs("audios")
history = [] # L∆∞u d∆∞·ªõi d·∫°ng list of dictionaries

def tts_and_save(text, model_choice, length_scale, noise_scale, noise_w, sentence_silence):
    audio_path = text_to_speech(text, model_choice, length_scale, noise_scale, noise_w, sentence_silence)
    
    table = history

    # N·∫øu th·∫•t b·∫°i (audio_path l√† None), tr·∫£ v·ªÅ None cho audio v√† history c≈©
    if audio_path is None:
        return None, list(reversed(table)), list(reversed(table))

    # N·∫øu th√†nh c√¥ng
    if not os.path.exists("audios"):
        os.makedirs("audios")
        
    filename = f"audios/{len(history)+1}.wav"
    os.rename(audio_path, filename)
    
    history.append({
        "Text": text,
        "Model": model_choice,
        "Audio": filename
    })

    # Tr·∫£ v·ªÅ 3 output: audio_path, table1, table2
    return filename, list(reversed(history)), list(reversed(history))
    
# --- CSS ---
custom_css = """

/* T√¥ng m√†u t·ªëi, ·∫•m √°p, sang tr·ªçng */
.gradio-container {
    background: linear-gradient(135deg, #1c1c1c, #243b55, #141e30);
    color: #d1f7ff;
}
/* Header ch√≠nh - Hi·ªáu ·ª©ng √Ånh s√°ng sao */
#header {
font-size: 28px;
    font-weight: bold;
    text-align: center;
    padding: 15px;
    border-radius: 12px;
    /* Hi·ªáu ·ª©ng t·ªèa s√°ng ·∫•m √°p */
    text-shadow: 0 0 10px #ff7e5f, 0 0 20px #ff7e5f;  
    color: white;  
}

/* Button ch√≠nh - N·ªïi b·∫≠t */
#submit-btn { 
    background: linear-gradient(90deg, #ff7e5f, #feb47b); /* Cam ·∫•m */
    color: #333; 
    font-weight: 900; 
    border-radius: 12px;
    box-shadow: 0 4px 20px rgba(255,126,95,0.4); /* Shadow r·ª±c r·ª° h∆°n */
}

/* Khung input/output */
.gr-textbox, .gr-slider, .gr-text-input, textarea, input { 
    background: rgba(255,255,255,0.05) !important; /* G·∫ßn nh∆∞ trong su·ªët tr√™n n·ªÅn t·ªëi */
    color: #fff !important; 
    border: 1px solid #ff7e5f44 !important; /* Vi·ªÅn m·ªù m√†u nh·∫•n */
    box-shadow: 0 2px 8px rgba(0,0,0,0.4) !important;
}

/* Nh√£n label */
label { 
    color: #feb47b !important; /* M√†u nh·∫•n ·∫•m √°p */
}

/* Output text (Gi·ªØ l·∫°i ID cho c√°c th√†nh ph·∫ßn kh√°c s·ª≠ d·ª•ng) */
#output_text { 
    color: #333; 
    font-weight: bold; 
    background: rgba(255,255,255,0.85); 
    border-radius: 10px; 
    padding: 8px;
}

/* Dataframe l·ªãch s·ª≠ */
.gr-dataframe { 
    background: rgba(255,255,255,0.9) !important; 
    color: #222 !important; 
    border-radius: 10px !important;
    font-size: 14px;
    box-shadow: 0 2px 8px rgba(0,0,0,0.15);
}

"""

    # --- UI ---
initial_history_table_value = [{"Text": "", "Model": "", "Audio": ""}]

with gr.Blocks(title="üé§ Vietnamese Piper TTS - Storyteller", theme=gr.themes.Soft(), css=custom_css) as demo:
    gr.Markdown("<h1 id='header'>üìñ K·ªÉ Chuy·ªán Ng·∫Øn v·ªõi Gi·ªçng ƒê·ªçc AI (Piper)</h1>", elem_id="header")

    with gr.Tabs():
        # üü£ TAB 1: K·ªÇ CHUY·ªÜN & C·∫§U H√åNH
        with gr.TabItem("üéß T·∫°o Gi·ªçng K·ªÉ Chuy·ªán"):
            with gr.Row():
                # --- C·ªòT 1: NH·∫¨P LI·ªÜU & N·ªòI DUNG ---
                with gr.Column(scale=2):
                    gr.Markdown("## üìù N·ªôi dung Truy·ªán")
                    mode = gr.Radio(
                        ["Ch·ªçn truy·ªán c√≥ s·∫µn", "Nh·∫≠p vƒÉn b·∫£n"], 
                        value="Ch·ªçn truy·ªán c√≥ s·∫µn", 
                        label="Ch·∫ø ƒë·ªô nh·∫≠p li·ªáu"
                    )
                    story_dropdown = gr.Dropdown(
                        choices=list(STORIES.keys()),
                        value=list(STORIES.keys())[0],
                        label="Ch·ªçn truy·ªán"
                    )
                    story_preview = gr.Textbox(
                        label="N·ªôi dung truy·ªán (c√≥ th·ªÉ ch·ªânh s·ª≠a)",
                        lines=12,
                        interactive=True
                    )
                    text_input = gr.Textbox(
                        label="Nh·∫≠p vƒÉn b·∫£n t√πy √Ω", 
                        lines=12,
                        visible=False
                    )

                # --- C·ªòT 2: C·∫§U H√åNH GI·ªåNG N√ìI & OUTPUT ---
                with gr.Column(scale=1):
                    gr.Markdown("## ‚öôÔ∏è C·∫•u h√¨nh Gi·ªçng n√≥i")
                    model_dropdown = gr.Dropdown(
                        choices=list(MODEL_CHOICES.keys()),
                        value="VAIS1000 Medium",
                        label="Ch·ªçn gi·ªçng ƒë·ªçc"
                    )
                    length_scale = gr.Slider(0.1, 2.0, value=0.7, label="T·ªëc ƒë·ªô n√≥i (Length Scale)")
                    noise_scale = gr.Slider(0.1, 1.5, value=0.8, label="ƒê·ªô bi·ªÉu c·∫£m (Noise Scale)")
                    noise_w = gr.Slider(0.1, 1.5, value=0.8, label="ƒê·ªô ·ªïn ƒë·ªãnh (Noise W)")
                    sentence_silence = gr.Slider(0.0, 2.0, value=0.5, label="Kho·∫£ng l·∫∑ng (Sentence Silence)")
                    
                    submit_btn = gr.Button("‚ñ∂Ô∏è K·ªÉ Truy·ªán (T·∫°o Audio)", elem_id="submit-btn")
                    
                    gr.Markdown("---")
                    gr.Markdown("## üîä K·∫øt qu·∫£")
                    # D√πng Label ƒë·ªÉ gi·ªØ b·ªë c·ª•c, nh∆∞ng n√≥ s·∫Ω tr·∫£ v·ªÅ r·ªóng theo logic m·ªõi
                    output_message = gr.Label("", elem_id="output_text") 
                    audio_output = gr.Audio(label="Audio ƒê·∫ßu Ra", type="filepath")
                    
            gr.Markdown("### üìú L·ªãch s·ª≠ Phi√™n l√†m vi·ªác (Session History)")
            history_table = gr.Dataframe(
                headers=["Text", "Model", "Audio"], 
                datatype=["str","str","file"], 
                row_count=(1,10),
                value=initial_history_table_value
            )

        # üü¢ TAB 2: L·ªäCH S·ª¨ T·ªîNG QUAN
        with gr.TabItem("üìñ L·ªãch S·ª≠ ƒê√£ T·∫°o"):
            gr.Markdown("‚ö° L·ªãch s·ª≠ text ‚Üí audio (m·ªõi nh·∫•t l√™n tr√™n)")
            history_table2 = gr.Dataframe(
                headers=["Text", "Model", "Audio"], 
                datatype=["str","str","file"], 
                row_count=(1,10),
                value=initial_history_table_value
            )

    # --- Logic ---
    def show_story(story_name):
        return STORIES[story_name]

    story_dropdown.change(show_story, inputs=story_dropdown, outputs=story_preview)

    # ·∫®n/hi·ªán textbox & dropdown khi ƒë·ªïi ch·∫ø ƒë·ªô
    def toggle_input_mode(mode):
        if mode == "Nh·∫≠p vƒÉn b·∫£n":
            return gr.update(visible=False), gr.update(visible=False), gr.update(visible=True)
        else:
            return gr.update(visible=True), gr.update(visible=True), gr.update(visible=False)

    mode.change(
        toggle_input_mode, 
        inputs=mode, 
        outputs=[story_dropdown, story_preview, text_input]
    )

    # Khi nh·∫•n "T·∫°o gi·ªçng n√≥i"
    def read_text_or_story(mode, story_name, story_preview_content, custom_text, model_choice, length_scale, noise_scale, noise_w, sentence_silence):
        
        text = ""
        if mode == "Nh·∫≠p vƒÉn b·∫£n":
            text = custom_text.strip()
        else:
            text = story_preview_content.strip()
        
        # Output cho output_message s·∫Ω l√† chu·ªói r·ªóng khi th√†nh c√¥ng/th·∫•t b·∫°i
        empty_msg = "" 
        
        if not text:
            # N·∫øu text r·ªóng, tr·∫£ v·ªÅ th√¥ng b√°o l·ªói, audio None, v√† table kh·ªüi t·∫°o
            return "‚ö†Ô∏è Vui l√≤ng nh·∫≠p n·ªôi dung!", None, initial_history_table_value, initial_history_table_value
            
        # H√†m tts_and_save tr·∫£ v·ªÅ 3 gi√° tr·ªã (audio, table1, table2)
        audio, table1, table2 = tts_and_save(text, model_choice, length_scale, noise_scale, noise_w, sentence_silence)
        
        # N·∫øu audio l√† None (th·∫•t b·∫°i), tr·∫£ v·ªÅ th√¥ng b√°o l·ªói chung
        if audio is None:
             error_msg = "‚ùå L·ªói: Kh√¥ng th·ªÉ t·∫°o audio. Ki·ªÉm tra console."
             return error_msg, None, table1, table2
        
        # Tr·∫£ v·ªÅ msg r·ªóng khi th√†nh c√¥ng
        return empty_msg, audio, table1, table2
        
    submit_btn.click(
        read_text_or_story,
        # C·∫≠p nh·∫≠t danh s√°ch inputs ƒë·ªÉ th√™m story_preview
        inputs=[mode, story_dropdown, story_preview, text_input, model_dropdown, length_scale, noise_scale, noise_w, sentence_silence],
        # Outputs: msg, audio, table1, table2
        outputs=[output_message, audio_output, history_table, history_table2], 
    )


if __name__ == "__main__":
    demo.launch()
